{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMG2KGGIgT+Yp2D0t4mpQnx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaeunfalo16/Deep_Learning/blob/master/LogisticClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndT7QhDyZiE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "8e40d080-5048-4843-a4ba-b9aa73a7434a"
      },
      "source": [
        "#Training data\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "\n",
        "#Placehoder for tensor that will be always fed by fed_dict\n",
        "X = tf.placeholder(tf.float32, shpae = [None, 2])\n",
        "Y = tf.placeholder(tf.float32, shpe = [None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal[2, 1], name = 'weight')\n",
        "b = tf.Varaible(tf.random_normal[1], name = 'bias')\n",
        "\n",
        "#Hypothesis using sigmoid : tf.div(1., 1. + tf.exp(tf.matmul(X, W) + b))\n",
        "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
        "\n",
        "#Cost/Loss function\n",
        "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
        "\n",
        "train = tf.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
        "\n",
        "#Accuracy computation\n",
        "#True if hypothesis > 0.5 else False\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(Y, predicted)), dtype = tf.float32)\n",
        "\n",
        "with tf.Session() as sess\n", // 'with' problem
        "  sess.run(tf.globalvariablesinitializer())\n",
        "\n",
        "  for step in range(2001) :\n",
        "    cost_val, _ = sess.run([cost, train], feed_dict = [X: x_data, Y: y_data])\n",
        "    if step % 200 == 0 :\n",
        "      print(step, cost_val)\n",
        "\n",
        "  h, c, a = ([hypothesis, predicted, accuracy], feed_dict = [x: x_data, Y: y_data])\n",
        "  print(\"Hypothesis : \\n\", h, \"Predicted : \\n\", c, \"Accuracy : \\n\", a)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-db75e277041c>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    with tf.Session() as sess\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}
